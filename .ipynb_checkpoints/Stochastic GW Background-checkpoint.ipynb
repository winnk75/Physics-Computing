{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven Stochastic GW Background Model - Is the background red?\n",
    "\n",
    "Winn Koster  |  wkoster@haverford.edu  |  Originally written as part of a problem set for Astro 344: Gravitational Waves\n",
    "\n",
    "In this project, we use data and simulation to create a model for a stochastic gravitational wave background. At the end we can more or less show that the data is dominated by a few strong sources, so the stochastic model is more jagged than red or blue. This simulation definitely overestimates the residuals, but my understanding is that NanoGrav is actually having problems with this assumption of an isotropic GW local background. Anyway, back to the project.\n",
    "\n",
    "We take local galaxies ($V_{radial} \\ < \\ 3000 \\ Km \\ s^{-1}$) and use data for these galaxies in two ways:\n",
    "\n",
    "We determine a mass from the velocity dispersion function using Ferrarese et al. (2000):\n",
    "\n",
    "$M_{bh} \\ $~$ \\ \\sigma^{4.8}$\n",
    "\n",
    "$log_{10} \\ M_{bh} \\ = \\ 4.80 \\ \\sigma \\ - \\ 2.9$\n",
    "    \n",
    "\n",
    "We determine a distance that we infer from the radial velocity, using Hubble's Law:\n",
    "\n",
    "$V_{rad}$ = $H_0 \\ d$\n",
    "\n",
    "I want to emphasize that this project is a proof of concept more than anything else. I'm playing fast and loose with the specifics of which rest frame I'm using, error bars on either the velocity dispursion or the radial velocity, and I'm sure a bunch of other things I haven't even thought of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start by loading the data from the .txt file. We obtained this using an SQL query and just saving as a text file.\n",
    "# database is found here: http://leda.univ-lyon1.fr/old_fullsql.html\n",
    "\n",
    "file_galaxies = './local-galaxies.txt'\n",
    "\n",
    "\n",
    "# MAKE SURE THIS IS A TRUE PLAINTEXT DOCUMENT! Changing .rtf to .txt is NOT going to cut it, since it will still carry a header.\n",
    "# Next two lines save arrays of the dispersion and the velocity wrt Galactic Standard of Rest\n",
    "vdis_galaxies = np.loadtxt(file_galaxies, skiprows=3, usecols=(1,))\n",
    "vgsr_galaxies = np.loadtxt(file_galaxies, skiprows=3, usecols=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(vdis_galaxies)\n",
    "print(vgsr_galaxies)\n",
    "\n",
    "print(str(len(vdis_galaxies))+' entries in dispersion function array')\n",
    "print(str(len(vgsr_galaxies))+' entries in radial velocity array')\n",
    "\n",
    "# Histograms, if you're curious\n",
    "#plt.hist(vdis_galaxies)\n",
    "#plt.hist(vgsr_galaxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to revisit the black hole mass equation from above:\n",
    "\n",
    "$log_{10} \\ M_{bh} \\ = \\ 4.80 \\ \\sigma \\ - \\ 2.9$\n",
    "\n",
    "Solving for the black hole mass, we find the following, expressed in units of $M_\\star$ and $Km \\ s^{-1}$.\n",
    "\n",
    "$M_{bh} \\ = \\ 0.00126 \\ \\sigma^{4.80}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn velocity dispersions into black hole masses, but add a little gaussian randomness just for fun...\n",
    "\n",
    "smbh_mass = []\n",
    "\n",
    "i=0\n",
    "while (i < 1278):\n",
    "    #smbh_mass.append(0.00125*((0.25*np.random.rand()*vdis_galaxies[i] + vdis_galaxies[i])**4.80))      # pseudorandom samples (less fun)\n",
    "    smbh_mass.append(0.00125*((0.002*np.random.normal(loc=vdis_galaxies[i],scale=0.1*vdis_galaxies[i])*vdis_galaxies[i] + vdis_galaxies[i])**4.80))    # Gaussian random samples (more fun)   \n",
    "    i=i+1\n",
    "    \n",
    "print(np.shape(smbh_mass))\n",
    "\n",
    "# Dank plots\n",
    "plt.loglog(vdis_galaxies,smbh_mass, ls='none', marker='o', markersize='1')\n",
    "plt.title('Black Hole Mass Power Law')\n",
    "plt.ylabel('Black Hole Mass [$M_\\star$]')\n",
    "plt.xlabel('Velocity Dispersion $\\sigma$ [$Km \\ s^{-1}$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the distribution of black hole masses. At the lower limit it looks a little weird (black holes the mass of the Earth, anyone?) but those won't do much to our strain so we don't really care. In the next section, we combine the black hole mass array with the radial velocity array (which we've ignored up to this point) in order to get a strain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating distance using H_0 = 72.3 from Riess et al 2016     https://arxiv.org/abs/1604.01424\n",
    "\n",
    "H_0 = 72.3\n",
    "\n",
    "# Galaxy distance in Mpc\n",
    "galaxy_distance = vgsr_galaxies / H_0\n",
    "\n",
    "print(np.min(galaxy_distance))\n",
    "print(np.max(galaxy_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experienced may note that this isn't a perfect science for local galaxies. Indeed, the minimum distance value turns out to be a negative number. Recall that the Andromeda galaxy is hurtling toward us at a fairly insane velocity. Since I'm not out to do any real science with this, I feel fully comfortable just taking the absolute value and moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_distance = np.abs(galaxy_distance)\n",
    "\n",
    "print(np.min(galaxy_distance))\n",
    "print(np.max(galaxy_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I teach myself how to use astrooy units again. I haven't used these since UCD, but they're super helpful (especially for converting between coordinate systems). I ended up NOT using astropy.units because they don't let you do things like cosine unless you supply it with angle units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strain_ampl = -(8*(omega**2)*smbh_mass*(r**2))/galaxy_distance\n",
    "#strain = strain_ampl*np.cos(4*np.pi*omega + phase)\n",
    "\n",
    "# omega will be randomized, so we can determine R based on Kepler's law...\n",
    "\n",
    "a = [1,2,3]\n",
    "a = a * u.solMass\n",
    "print(a)\n",
    "\n",
    "a = a.to(u.kg)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The great SI unit conversion...\n",
    "# BEWARE this cannot be run multiple times, since once the units are specified you can't just overwrite them again. I think.\n",
    "\n",
    "print(\"Converting SMBH Mass from Solar Masses into Kilograms...\")\n",
    "smbh_mass = smbh_mass * u.solMass\n",
    "print(smbh_mass[0])\n",
    "smbh_mass = smbh_mass.to(u.kg)\n",
    "print(smbh_mass[0])\n",
    "print(\" \")\n",
    "\n",
    "print(\"Converting Galaxy Distance from Megaparsecs into Meters...\")\n",
    "galaxy_distance = (galaxy_distance*1000000) * u.pc     # No Mpc so we multiply into pc\n",
    "print(galaxy_distance[0])\n",
    "galaxy_distance = galaxy_distance.to(u.meter)\n",
    "print(galaxy_distance[0])\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's get some random frequencies (omegas), sampled between 1 month and 100 years...\n",
    "# Random numbers between 1 and 1200 months -> np.random()*1199 + 1\n",
    "\n",
    "period = 1199*np.random.rand(1278) + 1\n",
    "\n",
    "plt.hist(period) # Just to verify that it's truly (mostly) random and evenly distributed...\n",
    "# So apparently astropy has FORTNIGHT but NOT MONTH?!?!? Ooooooookay then.\n",
    "\n",
    "\n",
    "period = (2*period) * u.fortnight\n",
    "print('Converting orbital period from Fortnights (no, seriously) to Seconds...')\n",
    "print(period[0])\n",
    "period = period.to(u.second)\n",
    "print(period[0])\n",
    "print(\" \")\n",
    "\n",
    "freq = period**(-1)\n",
    "omega = 2*np.pi*freq\n",
    "\n",
    "print(omega) # They're all in nanohertz!!\n",
    "\n",
    "# cheeky test just to see...\n",
    "print (\"Periods in years (even though it says seconds)\")\n",
    "print (1/omega/(2*np.pi*3.15e7))  #That looks reasonable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to determine the strain, but first we need the orbital radius. For this, I'll just plug into Kepler's law.\n",
    "\n",
    "$T \\ = \\ 2 \\pi \\ ( \\ a^3 \\ / \\ G \\ (M_1 \\ + \\ M_2) \\ )^{1/2}$\n",
    "\n",
    "\n",
    "Note that this implies no General Relatavistic correction, which in all honesty, is probably not an assumption we can make. We may also substitute radius for semi-major axis in the circular orbit case.\n",
    "\n",
    "$a \\ = \\ r$\n",
    "\n",
    "$( \\ ( T / 2 \\pi )^2 \\ (G M_{tot}) \\ )^{1/3} \\ = \\ r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orb_radius = (((period/(2.*np.pi))**2.)*((6.67)*(10.**-11.))*smbh_mass)**(1./3.)\n",
    "print(orb_radius)\n",
    "\n",
    "print(np.mean(orb_radius))\n",
    "print(np.std(orb_radius))\n",
    "print(np.min(orb_radius))\n",
    "# ignore the units, I couldn't get astropy's G to work so I added a scalar value instead..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 3.0*(10**8)\n",
    "\n",
    "#strain_ampl = -(8*(omega**2)*smbh_mass*(orb_radius**2)*)/galaxy_distance\n",
    "strain_ampl = (32.*(np.pi**2)*(6.67*(10**-11))*smbh_mass*(orb_radius**2)*(freq**2))/(galaxy_distance*(c**4))\n",
    "#ANL: so strain is proportional to mr^2/period^2\n",
    "#and once you put in for r^2 which is proportional to period^4/3 and M^2/3 then you\n",
    "#get strain proportional to M^5/3/period^2/3.   Yup, that's right! Just checking.\n",
    "\n",
    "print(strain_ampl)\n",
    "print (\"Min Max of Strain\")\n",
    "print (np.min(strain_ampl), np.max(strain_ampl))\n",
    "\n",
    "strain_residuals_ampl = strain_ampl*period\n",
    "#print(strain_residuals_ampl)       # Units lie, these are in seconds. Which makes sense.\n",
    "print (\"Min Max of residual amplitude\")\n",
    "print (np.min(strain_residuals_ampl), np.max(strain_residuals_ampl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(freq.value)\n",
    "\n",
    "#print(freq.unit)\n",
    "#print(time.unit)\n",
    "\n",
    "#strain_residuals_ampl[1].value\n",
    "\n",
    "#np.cos(2*np.pi*float(freq[0]*time[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase = (np.random.rand(1278))*2.0*np.pi    # Generates random phases between 0 and 2 pi\n",
    "\n",
    "# Builds a time axis to sum through\n",
    "time = 730.0*np.arange(1000001.0) *u.second   #creates 1,000,000 time enteries, each 730 seconds apart. This comes out to twenty minute resuloution for 30 years of data\n",
    "#print(time)\n",
    "\n",
    "# Sanitize the terms with units attached, since the units like to screw everything up\n",
    "strain_residuals_ampl = strain_residuals_ampl.value\n",
    "freq = freq.value\n",
    "    \n",
    "print(strain_residuals_ampl)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strain_summation = np.zeros(len(time))   # Creates an array to write summed values into\n",
    "time = time.value                        # Sanitizes the time array\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Proof that we only need 1 loop and that np.sum is smart enough to figure things out\n",
    "\n",
    "i=0\n",
    "summation = []\n",
    "while i < len(strain_residuals_ampl):\n",
    "    summation.append(strain_residuals_ampl[i]*np.cos(2*np.pi*freq[i]*time[0] + phase[i]))\n",
    "    i=i+1\n",
    "    \n",
    "print(summation[0:9]) #ANL:  Printed out the first 10 elements only to make it less unwieldy\n",
    "print(np.sum(summation))\n",
    "print(np.sum( strain_residuals_ampl*np.cos(2*np.pi*freq*time[0] + phase) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looping through the time coordinate\n",
    "\n",
    "i=0\n",
    "while (i < len(time)):\n",
    "    strain_summation[i] = np.sum( strain_residuals_ampl*np.cos(2*np.pi*freq*time[i] + phase) )\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting in new cell so I can generate new plots quickly and leave the summation (which takes about a minute) alone.\n",
    "\n",
    "plt.plot(time,strain_summation,ls='none',marker='.',markersize=1)\n",
    "plt.xlabel(\"Time [seconds]\")\n",
    "plt.ylabel(\"Residuals [seconds]\")\n",
    "plt.title(\"30 Years of Simulated Residuals Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the homework stopped here, we haven't actually determined whether or not the background is actually red! In the cells below I perform a quick Fourier Transform to see that the power law is negative excluding a strong peak at the upper limit of the plot, which I attribute to windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_trans = np.fft.fft(strain_summation*np.hamming(len(strain_summation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(f_trans))\n",
    "freq_axis = np.arange(1000001.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obviously we had to print in red...\n",
    "plt.loglog(freq_axis,np.real(f_trans),ls='none',marker='o',markersize=1,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
